#!/bin/bash

set -e # exit immediately if a simple command exits with a non-zero status
set -u # report the usage of uninitialized variables

<%
  require 'json'

  def discover_external_ip
    networks = spec.networks.marshal_dump
    _, network = networks.find do |_name, network_spec|
      network_spec.default
    end
    if !network
      _, network = networks.first
    end
    if !network
      raise "Could not determine IP via network spec: #{networks}"
    end
    network.ip
  end
%>

# Setup env vars and folders for the spark-slave_ctl script
source /var/vcap/jobs/spark-slave/helpers/ctl_setup.sh 'spark-slave'

mkdir -p $LOG_DIR
mkdir -p $RUN_DIR
mkdir -p $SPARK_WORK_DIR

# Set the hostname
hostname <%=discover_external_ip %>

<%
  masters = []
  link('spark-master').instances.each do |instance|
    masters << "#{instance.address}:#{link('spark-master').p('spark.master.port')}"
  end
%>

case $1 in

  start)

    chown --recursive vcap:vcap $SPARK_HOME
    chown --recursive vcap:vcap $LOG_DIR
    chown --recursive vcap:vcap $SPARK_WORK_DIR
    chown --recursive vcap:vcap $SPARK_PACKAGE_DATA

    exec chpst -u vcap:vcap $SPARK_HOME/bin/spark-class org.apache.spark.deploy.worker.Worker \
         spark://<%= masters.join(',') %> --webui-port 8089 \
         1>>$LOG_DIR/$JOB_NAME.stdout.log \
         2>>$LOG_DIR/$JOB_NAME.stderr.log &


    # store pid in $PIDFILE
    echo $! > $PIDFILE
    ;;

  stop)
    kill `cat $PIDFILE`

    ;;
  *)
    echo "Usage: spark-slave_ctl {start|stop}"

    ;;

esac
exit 0
